{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BZ6/PINDeepLearning/blob/main/%D0%9B%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%D1%82%D0%BE%D1%80%D0%BD%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%962.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В рамках этой лабораторной работы будут использоваться сверточные нейронные сети. Набор библиотек прежний, импортируйте все необходимые слои и т.п., задачи - классификация на изображениях."
      ],
      "metadata": {
        "id": "_lKqK1wS6iYI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfL7Eg946apn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В первую очередь вернемся к MNIST и решим вё ту же задачу классификации изображений, используя сверточную архитектуру. Также допускается использование Dropout, pooling, flatten. Выходной слой - полносвязный. Значение точности выше 98% считается удовлетворительным для выполнения этого пункта. Постройте кривые обучения для обучающей и валидационной выборок.  "
      ],
      "metadata": {
        "id": "qOW_kxO87bgx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dm3-WnfG85F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пока мы не отошли от MNIST, на этом же датасете обучите автоэнкодер, выходом которого должны быть картинки того же размера. Выведете несколько исходных картинок в паре с их обработанными вариантами по итогу обучения."
      ],
      "metadata": {
        "id": "HhHhZjWx-BNW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sl1mJrQu-A3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь - задача бинарной классификации. Импортируйте датасет по ссылке: https://www.kaggle.com/datasets/tongpython/cat-and-dog. Можно загрузить его на google drive или же подгрузить прямо по ссылке с помощью библиотеки opendatasets. Выполните классификацию с помощью обычной сверточной сети, resnet50 (weights=None) и vgg16. Сравните динамику (на кривых обучения), скорость и конечные результаты обучения."
      ],
      "metadata": {
        "id": "8qiRm1c-8563"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w9Pi_J4s_i_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iKb8trasB781"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F_ymf7u6B7uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь остановимся на архитектуре, включающей в себя resnet, и рассмотрим два способа дополнения обычной модели. Во-первых, можно аугментировать данные. Ознакомьтесь со слоями аугментации (https://keras.io/api/layers/preprocessing_layers/image_augmentation/) и обучите модель уже на модифицированных изображениях с нуля, но с сохранением той же архитектуры и тех же параметров обучения. Сравните с исходным результатом. (Ссылка для pytorch: https://pytorch.org/vision/stable/transforms.html)"
      ],
      "metadata": {
        "id": "Gsr3GsQNCYp_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7IGFu7PFIP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, используйте перенос обучения. Для этого достаточно просто установить параметр weights='imagenet'. Перенос обучения позволяет установить веса в начале обучения определенным образом вместо рандомной инициализации, в данном случае используются веса resnet50, обученного на датасете imagenet. Точно также обучите сеть, сохраняя все остальные параметры, на немодифицированных данных, и сравните результаты."
      ],
      "metadata": {
        "id": "npbe5b5uFI_l"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4ZsLI3WHF-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}